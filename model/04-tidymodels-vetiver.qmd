---
title: "Tidymodels and Vetiver"
format: html
editor_options: 
  chunk_output_type: console
  canonical: true
---

## Goals

The goals of this activity are to:

-   Create two models using the `tidymodels` framework that predict Posit Cola sales.
-   Save a model as a pin to Posit Connect using the `vetiver` package.
-   Deploy a model to Posit Connect as an API using the `vetiver` package.
-   Learn how to version and monitor your machine-learning models using `vetiver`.

## Overview

1.  Import validated posit-cola sales dataset from the database.
2.  Transform the data for modeling.
3.  Create `logistic_reg()` and `xgboost()` classification models using `tidymodels`.
4.  Assess the performance of both models using `tidymodels`.
5.  Save each model as a pin to Posit Connect using the `vetiver` package.
6.  Use the pinned models to serve a plumber API hosted on Posit Connect.
7.  Use the `vetiver` and `pins` package to version and monitor the performance of the models over time.

## Task 0 - Create and Save a Posit Connect API Key

Before starting this activity, we need to create and save a Posit Connect API key in our environment. This API key identifies you to Connect, allowing you to publish or interact with privileged content if you have the necessary permissions. **YOU SHOULD NEVER ADD YOUR API KEY TO YOUR SOURCE CODE!!!** An API key is like a password, and you should take the necessary steps to secure it. One of those methods is by adding it as an environment variable. You can do this by adding the variable/API key to your `.Renviron` file. This file is interpreted by R every time you start a new session. The `usethis` R packabe makes it super easy to add environment variables.

```{r}
#| eval: false

# Open your .Renviron file
usethis::edit_r_environ()
```

Once you run the above command, you should see a new file open up in RStudio. This is your `.Renviron` file and is usually located in your home (\~) directory. Before we set the variable, we first need to obtain an API key from Connect. Follow the steps below:

1.  Navigate to Posit Connect (TODO: add URL for Connect Server).
2.  Click your username in the top right corner.
3.  Select **API Keys**
4.  Select **+New API Key**
5.  Name it whatever you like. `Connect-API-Key` is a good option.
6.  Copy the new API key. **DON'T LOSE IT!** If you do lose it, you can create another one.

Navigate back to your `.Renviron` file and add the following line. It's always a good idea to add an additional blank line at the end of your `.Renviron` file. Let's also add the CONNECT_SERVER URL just for good measure!

```         
CONNECT_API_KEY=paste-your-api-key-here
CONNECT_SERVER=TODO: Add URL for Connect Server
```

Now you can close the `.Renviron` file and restart your R session (Session–\>Restart R) so that the API key varialble get's added to our environment. To confirm it worked, try running the following code:

```{r}
# Check if CONNECT_API_KEY is added to environment
Sys.getenv("CONNECT_API_KEY")

# Check if CONNECT_SERVER is added to environment
Sys.getenv("CONNECT_SERVER")
```

You should see the API key in the console. If not, please raise your hand and we'll be around to help you out!

## Task 1 - Create a tidymodel

```{r}
#| label: setup

library(tidymodels)
library(dplyr)
library(readr)
library(vetiver)
library(pins)
```

[Tidymodels](https://www.tidymodels.org/) is a collection of R packages for modeling and machine learning using [tidyverse](https://www.tidyverse.org/) principles. While this workshop is **not** a modeling workshop, to demonstrate the utility of the `vetiver`, we need to create a model.

For this activity, we will train and fit a logistic regression model to predict revenue for Posit Cola sales. Later on, we will create another model using xgboost.

🔄 Tasks

-   Explore the `posit-cola-sales` dataset. Use any method you'd like to understand the data. Try functions like `glimpse()`, `str()`, and `View()`.

-   Create a logistic regression tidymodel that predicts `revenue`.

#### Read and Explore the Data

```{r}
#| label: read-data

# Read in the posit-cola sales data
posit_cola_data <- read_csv("data/posit_cola_sales_data_clean.csv")
```


```{r}
#| label: explore-data

# Explore the data
glimpse(posit_cola_data)
summary(posit_cola_data)
str(posit_cola_data)
View(posit_cola_data)
```

#### Prep Data for Modeling

Sometimes, you may need to transform the original dataset to make it conducive to modeling.

```{r}
#| label: prep-data

model_data <- posit_cola_data |> 
  select(units_sold, unit_price, product, region, store_type, revenue) |> 
  # Convert character variables to factors
  mutate(
    product = as.factor(product),
    region = as.factor(region),
    store_type = as.factor(store_type)
  )
```

#### Split Data

For modeling, you often split your data into a **training and testing** dataset. Before we do that, we'll first extract the last 500 rows, which will be used later on for model monitoring.

```{r}
#| label: split-data

# Split the data
set.seed(123)
data_split <- initial_split(model_data, prop = 0.8, strata = revenue)
train_data <- training(data_split)
test_data <- testing(data_split)

cat("Training set size:", nrow(train_data), "\n")
cat("Test set size:", nrow(test_data), "\n")
```

#### Create the recipe


```{r}
#| label: create-recipe

# Create a simple recipe
revenue_recipe <- recipe(revenue ~ ., data = train_data) |>
  # Create dummy variables for categorical predictors
  step_dummy(all_nominal_predictors()) |>
  # Normalize numeric predictors
  step_normalize(all_numeric_predictors())
```


#### Define model type

```{r}
#| label: define-model-type

# Specify the model (simple linear regression)
linear_model <- linear_reg() |>
  set_engine("lm") |>
  set_mode("regression")
```


#### Create the workflow

```{r}
#| label: create-workflow

revenue_workflow <- workflow() |> 
  add_recipe(revenue_recipe) |> 
  add_model(linear_model)
```

### Train the Model

Train the model using our training set.

```{r}
#| label: train-model

# Train the model
cat("Training model...\n")
fitted_model <- revenue_workflow |> 
  fit(data = train_data)

cat("Model training complete!\n")
```

#### Evaluate the Model

We'll use `tidymodels` to evaluate how our model did using the testing dataset.

```{r}
#| label: evaluate-model

# Make predictions on test set
predictions <- fitted_model |>
  predict(test_data) |>
  bind_cols(test_data)

# Calculate model performance
model_metrics <- predictions |>
  metrics(truth = revenue, estimate = .pred)

cat("\nModel Performance:\n")
print(model_metrics)
```

🛑 Stop here!

## Task 2 - Pin Model to Posit Connect

Now that we have a model, we'll want to save it to a location so that it can be easily shared with colleagues, other content, or your future self! The `pins` package is the workhorse behind this workflow. The `vetiver` package has some wrappers around the pinning functions that we'll use in this task.

🔄 Tasks

-   Create a vetiver model.

-   Pin vetiver model to Posit Connect.

#### Create a Vetiver Model and Pin to Posit Connect

Before we go any further, we need to convert our logistic regression model into a format that can be used by `vetiver`:

```{r}
#| label: create-vetiver-model

# Create a vetiver model
vetiver_model <- vetiver_model(
  model = fitted_model,
  model_name = "posit_cola_revenue_model"
)
```

And now we can save it, or *pin it*, to Posit Connect! Remember to define your pinning board as Posit Connect.

```{r}
#| label: pin-model

# Register Posit Connect as board
board <- board_connect()

# Write Vetiver Model

board |> vetiver_pin_write(vetiver_model)
```

Navigate to Posit Connect and check out your pinned model! You'll also notice a message asking you to create a **Model Card**. This is alsways a good idea, especially if you will be sharing your model with others. An example model card can be found here: `materials/04-tidymodels-vetiver/ferry_modelcard_r.Rmd`.

🛑 Stop here!

## Task 3 - Serve Model as an API

APIs are a great way for users, applications, or other systems to interact with your model. `vetiver` leverages [Plumber](https://www.rplumber.io/) which is used to create APIs with only R code! Let's create an API here within Posit Workbench, and then deploy it to Posit Connect.

🔄 Tasks

-   Deploy model to Posit Connect as an API.

-   Make a prediction using the API visual interface (RapiDoc).

-   Make a request to the API using R code.

#### Deploy API to Posit Connect

**Be sure to add your user name for the pin!**

**Be sure to add your user name for the pin!**

```{r}
#| label: create-api

# Create API from pinned model using vetiver
#  Swap out "____" for your username on Connect.
vetiver_deploy_rsconnect(board = board, name = "ryan/posit_cola_revenue_model")
```

Once it's deployed, navigate to the API on Posit Connect and give it a test run! Click the operation on the left called `Return predictions from model using 5 features`. Then copy any variation of the request below and click **Try**. You should see a response of the predicted revenue:

```
[
  {
    "units_sold": 150,
    "unit_price": 2.00,
    "product": "Sprite",
    "region": "Europe",
    "store_type": "Supermarket"
  }
]
```

#### Make a Prediction using R Code

On Posit Connect, navigate to your newly created API, and copy the URL for the content below. You can find this URL by clicking the access tab --\> URL.

```{r}
#| label: create-endpoint

api_url <- "https://connect.posit.it/content/d38c29b8-250f-4a22-ba05-4ff4a49f0304"

# Append "/predict" to the end of your api to create the endpoint
endpoint <- vetiver_endpoint(paste0(api_url, "/predict"))

endpoint
```

Below is a data frame representing information for a Posit Cola sale. Let's see what the predicted revenue will be. Feel free to modify.

```{r}
#| label: make-new-coke-sale-data

# Create new ferry data point
new_sale <- tibble(
  units_sold = 300,
  unit_price = 1.50,
  product = "Sprite",
  region = "Europe",
  store_type = "Supermarket"
)
```

Now we can use the `predict()` function to query the API so that it returns a revenue prediction. Note that we have to add our API key to the predict function since this API is only accessible to specific users!

```{r}
#| label: predict-r

# Predict from Vetiver endpoint
predict(endpoint, 
        new_sale,
        httr::add_headers(Authorization = paste("Key", Sys.getenv("CONNECT_API_KEY"))))$.pred
```

🛑 Stop here!

## Task 4 - Version and Monitor Model

Creating a model is an iterative process, and chances are you'll create multiple versions of your model along the way. You may even create a completely different model to address the same question. How then can you keep track of all these versions, and ensure that you're always using the best model for the job? Vetiver to the rescue 🦸!

Before we get started, we first need to make sure that the board we are using to pin our models can accommodate versioning. Fortunately, most boards, including Posit Connect, leverage versioning by default. If you want to explicitly turn on versions, just make sure you use the `versioned` argument when defining your board: `board_connect(versioned = TRUE)`.

Monitoring a model means you are assessing performance as new data comes in over time. During task 1, we pulled out the bottom 500 rows from our dataset, and saved it to the `monitoring_data` variable. This will simulate the "new" data for model monitoring!

🔄 Tasks

-   List model versions.

-   Monitor model performance using *new* sales data.

#### List Model Versions

We only have 1 version of our model, but let's list it anyway by using the `pin_versions()` function. Take note of the **version number (first column)!**

```{r}
#| label: list-pin-versions

# View versions of your model 
#  Replace "____" with your username 
pin_versions(board = board, name = "ryan/posit_cola_revenue_model")

# We can also extract some metadata from the pin
pin_meta(board = board, name = "ryan/posit_cola_revenue_model")$description
```

#### Create Another Model (Random forest)

Let's create another model to answer the same question as our logistic regression model: can we predict posit-cola sales revenue? The below code cell will create, train, and assess the performance of a regression model using the random forest engine. This model will be used to compare against our first model.

```{r}
#| label: create-rf-model

# Create a model using the random forest engine
library(parsnip)
linear_model_rf <- rand_forest(
  mode = "regression",
  trees = 100
) |>
  set_engine("ranger")

# Create a workflow
revenue_workflow_rf <- workflow() |> 
  add_recipe(revenue_recipe) |> 
  add_model(linear_model_rf)

# Train the model
cat("Training Random Forest model...\n")
fitted_model_rf <- revenue_workflow_rf |> 
  fit(data = train_data)
cat("Random Forest model training complete!\n")

# Make predictions on test set
predictions_rf <- fitted_model_rf |>
  predict(test_data) |>
  bind_cols(test_data)

# Calculate model performance
model_metrics_rf <- predictions_rf |>
  metrics(truth = revenue, estimate = .pred)

cat("\nRandom Forest Model Performance:\n")
print(model_metrics_rf)
```

#### Pin the random forest model to Posit Connect
Now that we have a new model, we can pin it to Posit Connect as well. This will allow us to version the model and monitor its performance over time. We'll pin it using the `vetiver` package to the same location as our previous model.

```{r}
#| label: pin-rf-model

# Create a vetiver model
vetiver_model_rf <- vetiver_model(
  model = fitted_model_rf,
  model_name = "posit_cola_revenue_model"
)

# Write Vetiver Model
board |> vetiver_pin_write(vetiver_model_rf)

# View versions of your model
pin_versions(board = board, name = "ryan/posit_cola_revenue_model")

# We can also extract some metadata from the pin
pin_meta(board = board, name = "ryan/posit_cola_revenue_model")$description
```

#### Monitor Model Performance

How do we know which model is performing better? Logistic regression or random forests? That's where model monitoring comes into play.

❗Be sure add in the version number as a string (eg. "557741").

```{r}
#| label: monitor-model-performance

# Read in monitoring data
monitoring_data <- read_csv("data/posit_cola_sales_monitoring_data.csv")

# Load the vetiver model
vetiver_model_lm <- vetiver_pin_read(board, "ryan/posit_cola_revenue_model", version = "757597")

# Load the vetiver model rf
vetiver_model_rf <- vetiver_pin_read(board, "ryan/posit_cola_revenue_model", version = "757619")

# Compute metrics for the logistic regression model
sales_revenue_metrics_lm <-
    augment(vetiver_model_lm, new_data = arrange(monitoring_data, date)) |> 
    vetiver_compute_metrics(
      date_var = date,
      period = "week",
      truth = revenue,
      estimate = .pred
    )

# Compute metrics for the rf model
sales_revenue_metrics_rf <-
    augment(vetiver_model_rf, new_data = arrange(monitoring_data, date)) |> 
    vetiver_compute_metrics(
      date_var = date,
      period = "week",
      truth = revenue,
      estimate = .pred
    )

# Plot the metrics for the logistic regression model
vetiver_plot_metrics(sales_revenue_metrics_lm) +
  scale_size(range = c(2, 4)) +
  labs(title = pin_meta(board = board, "ryan/posit_cola_revenue_model", version = "757597")$description)

# Plot the metrics for the GLM model
vetiver_plot_metrics(sales_revenue_metrics_rf) +
  scale_size(range = c(2, 4)) +
  labs(title = pin_meta(board = board, "ryan/posit_cola_revenue_model", version = "757619")$description)

```
